{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligente Agenten\n",
    "Beantworten Sie die folgenden Fragen!\n",
    "## Der Turing-Test\n",
    "1. Wie funktioniert der Turing-Test?\n",
    "2. Was braucht eine Maschine um den Test zu bestehen?\n",
    "3. Was ist der totale Turing-Test?\n",
    "4. Was braucht eine Maschine um den totalen Turing-Test zu bestehen?\n",
    "5. Welche Probleme existieren beim Turing-Test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenten\n",
    "1. Was ist ein Agent? Aus welchen Bestandteilen besteht ein Agent?\n",
    "2. Welche Arten von Agenten kennen Sie? Wie zeichnen Sich die einzelnen Agententypen aus?\n",
    "3. Durch welche Eigenschaften zeichnet sich eine Umgebung aus in der sich ein Agent bewegt?:<br/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Staubsauger als Agent\n",
    "Wir werden heute einen Staubsauger-Agenten und die dazugehörige Umgebung bzw. \"Welt\" programmieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst definieren wir uns eine Klasse \"Environment\". Diese Klasse repräsentiert unsere Welt in der sich der Agent bewegen soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InvalidActionError(Exception):\n",
    "    \"\"\"Is triggered, if the agent wants to execute an ivalid action.\"\"\"\n",
    "    pass\n",
    "\n",
    "class Environment:\n",
    "    \"\"\"Class representing an Environment. Other environment classes can\n",
    "    inherit from this. They typically need to implement:\n",
    "        percept:           Define the percept that an agent sees.\n",
    "        execute_action:    Define the effects of executing an action.\n",
    "                           Also update the agent.performance slot.\n",
    "    The environment keeps a dict of .loc_status which includes locations and their respective status. \n",
    "    There is also a list of .agents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.loc_status = {(0, 0): random.choice(['Clean', 'Dirty']),\n",
    "                          (0, 1): random.choice(['Clean', 'Dirty']),\n",
    "                          (1, 0): random.choice(['Clean', 'Dirty']),\n",
    "                          (1, 1): random.choice(['Clean', 'Dirty'])}\n",
    "        self.agents = []\n",
    "        self.time = 0\n",
    "\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Dirty/Clean).\"\"\"\n",
    "        return (agent.location, self.loc_status[agent.location])\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status\"\"\"\n",
    "        former_location = agent.location\n",
    "        if action == 'move_left' and agent.location[1] > 0:\n",
    "            agent.location = (agent.location[0], agent.location[1]-1)\n",
    "            print(f\"Moving left: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_right' and agent.location[1] < 1:\n",
    "            agent.location = (agent.location[0], agent.location[1]+1)\n",
    "            print(f\"Moving right: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_down' and agent.location[0] < 1:\n",
    "            agent.location = (agent.location[0]+1, agent.location[1])\n",
    "            print(f\"Moving down: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_up' and agent.location[0] > 0:\n",
    "            agent.location = (agent.location[0]-1, agent.location[1])\n",
    "            print(f\"Moving up: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'clean':\n",
    "            self.loc_status[agent.location] = 'Clean'\n",
    "            print(\"Cleaning: \", agent.location)\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'do_nothing':\n",
    "            print(\"Doing nothing at location:\", agent.location)\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        else:\n",
    "            error_message = f\"Invalid action '{action}' at position {former_location}!\"\n",
    "            raise InvalidActionError(error_message)\n",
    "            \n",
    "    \n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Agents start in either location at random.\"\"\"\n",
    "        return random.choice([(0,0), (0,1), (1,0), (1,1)])\n",
    "\n",
    "    def exogenous_change(self):\n",
    "        \"\"\"If there is spontaneous change in the world, override this.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do. If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        actions = []\n",
    "        \n",
    "        for agent in self.agents:\n",
    "            actions.append(agent.program(self.percept(agent)))\n",
    "        for (agent, action) in zip(self.agents, actions):\n",
    "            self.execute_action(agent, action)\n",
    "        self.exogenous_change()\n",
    "\n",
    "    def run(self, steps=10):\n",
    "        \"\"\"Run the Environment for given number of time steps.\"\"\"\n",
    "        print(\"Initial world state: \", self.loc_status)\n",
    "        for step in range(steps):\n",
    "            self.time += 1\n",
    "            self.step()\n",
    "            if all(value == \"Clean\" for value in self.loc_status.values()):\n",
    "                break\n",
    "\n",
    "    def add_agent(self, agent, location=None):\n",
    "        \"\"\"Add a thing to the environment, setting its location. For\n",
    "        convenience, if thing is an agent program we make a new agent\n",
    "        for it. (Shouldn't need to override this.)\"\"\"\n",
    "        if agent in self.agents:\n",
    "            print(\"Can't add the same agent twice\")\n",
    "        else:\n",
    "            agent.location = location if location is not None else self.default_location(agent)\n",
    "            self.agents.append(agent)\n",
    "\n",
    "    def delete_agent(self, agent):\n",
    "        \"\"\"Remove agent from the environment.\"\"\"\n",
    "        try:\n",
    "            self.agents.remove(agent)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"  in Environment delete_agent\")\n",
    "            print(\"  Agent to be removed: {} at {}\".format(agent, agent.location))\n",
    "            print(\"  from list: {}\".format([(agent, agent.location) for agent in self.agents]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann benötigen wir noch eine Klasse für unsere Agenten. Da wir im Laufe der Übung unterschiedliche Agenten implementieren möchten verwenden wir zunächst eine sogenannte \"abstrakte\" Klasse `TraceAgent`, von der unsere späteren konkreten Agent-Klassen erben können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TraceAgent:\n",
    "    \"\"\"An abstract class of an agent. Concrete agent classes wil inherit from this class and have to provide (at least) a program function.\n",
    "    Optionally you can also provide an __init__ function if the agent should have internal states.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loc_status = None\n",
    "        self.location = None\n",
    "        \n",
    "    def programm(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sehen wir nun eine mögliche Implementierung einer `SimpleAgent`-Klasse. Dabei erbt diese Klasse alle Methoden und Attribute von der abstrakten Klasse `TraceAgent` und überschreibt diese gegebenenfalls mit ihrer eigenen Logik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleAgent(TraceAgent):\n",
    "    def program(self, perception):\n",
    "        self.location, loc_status = perception\n",
    "        if loc_status == \"Clean\":\n",
    "            action = \"do_nothing\"\n",
    "        else:\n",
    "            action = \"clean\"\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun könnne wir uns mit folgender Zelle eine neue Welt erstellen und unseren `SimpleAgent`zu dieser Welt hinzufügen. Anschließend Simulieren wir 10 Zeitschritte in dieser Welt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = Environment()\n",
    "e.add_agent(SimpleAgent())\n",
    "e.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "Implementieren Sie die Klasse ReflexAgent als einfachen Reflex-Agenten. Das Verhalten können sie dabei selbst festlegen. Der Agent soll dabei in unserer Welt \"Environment\" funktionieren. Beachten Sie diesen Umstand bei der Festlegung möglicher Aktionen, die der Agent in der genannten Welt ausführen soll. Die Liste der Aktionen ist folgende: \"move_left\", \"move_right\", \"move_up\", \"move_down\", \"do_nothing\" und \"clean\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReflexAgent(TraceAgent):\n",
    "    def program(self, perception):\n",
    "        self.location, loc_status = perception\n",
    "        return \"Implement me!\"\n",
    "\n",
    "e1 = Environment()\n",
    "a1 = ReflexAgent()\n",
    "e1.add_agent(a1)\n",
    "e1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "Implementieren Sie die Klasse \"ModelBasedAgent\" als modellbasierten Agenten. Auch dieser Agent soll in der \"Environment\" funktionieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelBasedAgent(TraceAgent):\n",
    "    def __init__(self):\n",
    "        self.loc_status = {(0, 0): None,\n",
    "                           (0, 1): None,\n",
    "                           (1, 0): None,\n",
    "                           (1, 1): None}\n",
    "        self.location = None\n",
    "    def program(self, perception):\n",
    "        location, loc_status = perception\n",
    "        self.location = location\n",
    "        self.loc_status[self.location] = loc_status\n",
    "        \n",
    "        return \"Implement my logic!\"\n",
    "\n",
    "e2 = Environment()\n",
    "a2 = ModelBasedAgent()\n",
    "e2.add_agent(a2)\n",
    "e2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3\n",
    "Erweitern Sie die Implementierung der Environment, sodass es beliebig viele, auf einem 2D-Gitter angeordnete Positionen gibt. Erweitern Sie auch die Implementierung der beiden Agenten entsprechend, sodass diese sinnvoll in der neuen Umgebung agieren können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExtendedEnvironment(Environment):\n",
    "\n",
    "    \"\"\"This environment has nxn locations. Each can be Dirty\n",
    "    or Clean. The agent perceives its location and the location's\n",
    "    status. This serves as an example of how to implement a simple\n",
    "    Environment.\"\"\"\n",
    "\n",
    "    def __init__(self, grid_size: int):\n",
    "        super().__init__()\n",
    "        \"Implement me!\"\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status\"\"\"\n",
    "        \n",
    "        \"Implement me!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExtendedModelBasedAgent(TraceAgent):\n",
    "    def __init__(self, loc_status):\n",
    "        self.loc_status = \"Implement me!\"\n",
    "        self.location = None\n",
    "    def program(self, perception):\n",
    "        location, loc_status = perception\n",
    "        self.location = location\n",
    "        self.loc_status[self.location] = loc_status\n",
    "        \n",
    "        return \"Implement my logic!\"\n",
    "\n",
    "e4 = Environment()\n",
    "a4 = ExtendedModelBasedAgent(e4.loc_status)\n",
    "e4.add_agent(a4)\n",
    "e4.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lehre-oZkq39sg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
