{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligente Agenten\n",
    "## Der Turing-Test\n",
    "1. Wie funktioniert der Turing-Test?\n",
    "2. Was braucht eine Maschine um den Test zu bestehen?\n",
    "3. Was ist der totale Turing-Test?\n",
    "4. Was braucht eine Maschine um den totalen Turing-Test zu bestehen?\n",
    "5. Welche Probleme existieren beim Turing-Test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenten\n",
    "1. Was ist ein Agent? Aus welchen Bestandteilen besteht ein Agent?\n",
    "2. Diskutieren Sie die folgenden Begriffe. Geben Sie jeweils 2 Beispiele für:<br/>\n",
    "    a) Vollständig beobachtbare Umgebung.<br/>\n",
    "    b) Nichtdeterministische Umgebung.<br/>\n",
    "    c) Single-Agent Umgebung.<br/>\n",
    "    d) Multi-Agent Umgebung.<br/>\n",
    "    e) Umgebung mit diskretem Zustandsraum.<br/>\n",
    "    f) Umgebung mit kontinuierlichem Zustandsraum.<br/>\n",
    "    g) Einfache Reflex-Agenten.<br/>\n",
    "    h) Modellbasierte Reflex-Agenten.<br/>\n",
    "    i) Zielbasierte Agenten.<br/>\n",
    "    j) Lernfähige Agenten.<br/>\n",
    "3. Was ist Rationalität?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Staubsauger als Agent\n",
    "Wir werden heute einen Staubsauger-Agenten und die dazugehörige Umgebung bzw. \"Welt\" programmieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# (x, y) coordinates of the different locations \n",
    "loc_A, loc_B = (0, 0), (1, 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst definieren wir uns eine Klasse \"Thing\". Diese Klasse repräsentiert alle physischen Objekte, die in unserer Welt vorkommen können. Dabei kann ein Gegenstand entweder lebendig sein oder nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thing:\n",
    "    \"\"\"This represents any physical object that can appear in an Environment.\n",
    "    You subclass Thing to get the things you want. Each thing can have a\n",
    "    .__name__  slot (used for output only).\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<{}>'.format(getattr(self, '__name__', self.__class__.__name__))\n",
    "\n",
    "    def is_alive(self):\n",
    "        \"\"\"Things that are 'alive' should return true.\"\"\"\n",
    "        return hasattr(self, 'alive') and self.alive\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Display the agent's internal state. Subclasses should override.\"\"\"\n",
    "        print(\"I don't know how to show_state.\")\n",
    "\n",
    "    def display(self, canvas, x, y, width, height):\n",
    "        \"\"\"Display an image of this Thing on the canvas.\"\"\"\n",
    "        # Do we need this?\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Thing-Klasse benötigen wir dann später auch für unsere Umgebung. Zu diesem Zweck wird zunächst eine abstrakte Klasse \"Environment\" definiert, welche als \"Dummy\" für spätere konkrete Implementierungen verschiedener Umgebungen bzw. Welten dient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\"Abstract class representing an Environment. 'Real' Environment classes\n",
    "    inherit from this. Your Environment will typically need to implement:\n",
    "        percept:           Define the percept that an agent sees.\n",
    "        execute_action:    Define the effects of executing an action.\n",
    "                           Also update the agent.performance slot.\n",
    "    The environment keeps a list of .things and .agents (which is a subset\n",
    "    of .things). Each agent has a .performance slot, initialized to 0.\n",
    "    Each thing has a .location slot, even though some environments may not\n",
    "    need this.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return []  # List of classes that can go into environment\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Return the percept that the agent sees at this point. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change the world to reflect this action. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Default location to place a new thing with unspecified location.\"\"\"\n",
    "        return None\n",
    "\n",
    "    def exogenous_change(self):\n",
    "        \"\"\"If there is spontaneous change in the world, override this.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do. If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        actions = []\n",
    "        for agent in self.agents:\n",
    "            actions.append(agent.program(self.percept(agent)))\n",
    "        for (agent, action) in zip(self.agents, actions):\n",
    "            self.execute_action(agent, action)\n",
    "        self.exogenous_change()\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Run the Environment for given number of time steps.\"\"\"\n",
    "        for step in range(steps):\n",
    "            self.step()\n",
    "\n",
    "    def list_things_at(self, location, tclass=Thing):\n",
    "        \"\"\"Return all things exactly at a given location.\"\"\"\n",
    "        return [thing for thing in self.things\n",
    "                if thing.location == location and isinstance(thing, tclass)]\n",
    "\n",
    "    def some_things_at(self, location, tclass=Thing):\n",
    "        \"\"\"Return true if at least one of the things at location\n",
    "        is an instance of class tclass (or a subclass).\"\"\"\n",
    "        return self.list_things_at(location, tclass) != []\n",
    "\n",
    "    def add_thing(self, thing, location=None):\n",
    "        \"\"\"Add a thing to the environment, setting its location. For\n",
    "        convenience, if thing is an agent program we make a new agent\n",
    "        for it. (Shouldn't need to override this.)\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        if thing in self.things:\n",
    "            print(\"Can't add the same thing twice\")\n",
    "        else:\n",
    "            thing.location = location if location is not None else self.default_location(thing)\n",
    "            self.things.append(thing)\n",
    "            if isinstance(thing, Agent):\n",
    "                thing.performance = 0\n",
    "                self.agents.append(thing)\n",
    "\n",
    "    def delete_thing(self, thing):\n",
    "        \"\"\"Remove a thing from the environment.\"\"\"\n",
    "        try:\n",
    "            self.things.remove(thing)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"  in Environment delete_thing\")\n",
    "            print(\"  Thing to be removed: {} at {}\".format(thing, thing.location))\n",
    "            print(\"  from list: {}\".format([(thing, thing.location) for thing in self.things]))\n",
    "        if thing in self.agents:\n",
    "            self.agents.remove(thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun da wir uns abstrakten Klassen für Objekte und mögliche Welten programmiert haben, können wir damit beginnen eine konkrete Welt zu implementieren. Bei der folgenden Klasse handelt es sich um eine triviale Welt für einen Staubsauger-Roboter. Sie besteht aus nur zwei Locations (loc_A, loc_B) die beide jeweils nebeneinander liegen. Jede Location kann dabei entweder dreckig oder sauber sein.\n",
    "\n",
    "Weiterhin können in unserer Welt Wände, Schmutz und verschiedene Agenten als \"Things\" enthalten sein (thing_classes-Methode). Ebenfalls wird definiert, was der Agent in unserer Welt warnehmen kann (percept-Methode) und wie sich die möglichen Aktionen unseres Agenten auf die Welt auswirken (execute_action-Methode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrivialVacuumEnvironment(Environment):\n",
    "\n",
    "    \"\"\"This environment has two locations, A and B. Each can be Dirty\n",
    "    or Clean. The agent perceives its location and the location's\n",
    "    status. This serves as an example of how to implement a simple\n",
    "    Environment.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.status = {loc_A: random.choice(['Clean', 'Dirty']),\n",
    "                       loc_B: random.choice(['Clean', 'Dirty'])}\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return [Wall, Dirt, ReflexVacuumAgent, RandomVacuumAgent,\n",
    "                TableDrivenVacuumAgent, ModelBasedVacuumAgent]\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Dirty/Clean).\"\"\"\n",
    "        return (agent.location, self.status[agent.location])\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status; track performance.\n",
    "        Score 10 for each dirt cleaned; -1 for each move.\"\"\"\n",
    "        if action == 'Right':\n",
    "            agent.location = loc_B\n",
    "            agent.performance -= 1\n",
    "        elif action == 'Left':\n",
    "            agent.location = loc_A\n",
    "            agent.performance -= 1\n",
    "        elif action == 'Suck':\n",
    "            if self.status[agent.location] == 'Dirty':\n",
    "                agent.performance += 10\n",
    "            self.status[agent.location] = 'Clean'\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Agents start in either location at random.\"\"\"\n",
    "        return random.choice([loc_A, loc_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir uns nun mit der Implementierung der \"Welt\" und ihrer möglichen Ausprägungen auseinandergesetzt haben, kommen wir nun zu den eigentlichen Agenten. Dazu schaffen wir uns zunächst eine Klasse \"Agent\", welche wiederum eine Unterklasse von \"Thing\" ist. \n",
    "\n",
    "Dabei hat unser Agent nur ein einzelnes Attribut, welches das eigentlichen \"Verhalten\" des Agenten enthält. Beim Initialisieren eines neuen Agenten, muss diese \"Verhalten\" in Form einer Python-Funktion an die Agenten-Klasse übergeben werden. Dabei ist darauf zu achten, dass die übergebene Funktion als Argument eine \"Wahrnehmung\" bekommt und als Rückgabe eine (in der jeweiligen Welt mögliche) Aktion zurückliefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(Thing):\n",
    "    \"\"\"An Agent is a subclass of Thing with one required slot,\n",
    "    .program, which should hold a function that takes one argument, the\n",
    "    percept, and returns an action. (What counts as a percept or action\n",
    "    will depend on the specific environment in which the agent exists.)\n",
    "    Note that 'program' is a slot, not a method. If it were a method,\n",
    "    then the program could 'cheat' and look at aspects of the agent.\n",
    "    It's not supposed to do that: the program can only look at the\n",
    "    percepts. An agent program that needs a model of the world (and of\n",
    "    the agent itself) will have to build and maintain its own model.\n",
    "    There is an optional slot, .performance, which is a number giving\n",
    "    the performance measure of the agent in its environment.\"\"\"\n",
    "    def __init__(self, program):\n",
    "        self.program = program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion ermöglicht lediglich die Ausgabe der jeweiligen Wahrnehmung des Agenten und der daraus resultierenden Aktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TraceAgent(agent):\n",
    "    \"\"\"Wrap the agent's program to print its input and output. This will let\n",
    "    you see what the agent is doing in the environment.\"\"\"\n",
    "    old_program = agent.program\n",
    "\n",
    "    def new_program(percept):\n",
    "        action = old_program(percept)\n",
    "        print('{} perceives {} and does {}'.format(agent, percept, action))\n",
    "        return action\n",
    "    agent.program = new_program\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun definieren wir uns einen einfachen Agenten, der nichts macht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpleAgent():\n",
    "    \"\"\"A simple agent for the two-state vacuum environment which does nothing.\"\"\"\n",
    "    def program(percept):\n",
    "        loc, status = percept\n",
    "        return None\n",
    "    return Agent(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier nun ein Beispiel wie wir unseren Agenten aufrufen können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TraceAgent(SimpleAgent())\n",
    "a.program((loc_A, 'Clean'))\n",
    "a.program((loc_B, 'Clean'))\n",
    "a.program((loc_A, 'Dirty'))\n",
    "a.program((loc_A, 'Dirty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei haben wir allerdings noch keine Welt vorgegeben, sondern dem Agenten lediglich mit jedem Aufruf jeweils einen möglichen Zustand unserer zweidimensionalen Welt vorgegeben.\n",
    "\n",
    "Um unseren Agenten in der von uns definierten Umgebung interagieren zu lassen, müssen wir nun folgendes tun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize environment\n",
    "e = TrivialVacuumEnvironment()\n",
    "# add an agent to our environment\n",
    "e.add_thing(TraceAgent(SimpleAgent()))\n",
    "# execute our environment and the agent for five discrete timesteps\n",
    "e.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "Implementieren Sie die Klasse ReflexVacuumAgent als einfachen Reflex-Agenten. Das Verhalten können sie dabei selbst festlegen. Der Agent soll dabei in unserer Welt \"TrivialVacuumEnvironment\" funktionieren. Beachten Sie diesen Umstand bei der Festlegung möglicher Aktionen, die der Agent in der genannten Welt ausführen soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReflexVacuumAgent():\n",
    "    \"\"\"A reflex agent for the two-state vacuum environment.\"\"\"\n",
    "    def program(percept):\n",
    "        loc, status = percept\n",
    "        # TODO Aufgabe 1\n",
    "        return None\n",
    "    return Agent(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize environment\n",
    "e = TrivialVacuumEnvironment()\n",
    "# add an agent to our environment\n",
    "e.add_thing(TraceAgent(ReflexVacuumAgent()))\n",
    "# execute our environment and the agent for five discrete timesteps\n",
    "e.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "Implementieren Sie die Klasse \"ModelBasedVacuumAgent\" als modellbasierten Agenten. Auch dieser Agent soll in der \"TrivialVacuumEnvironment\" funktionieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelBasedVacuumAgent():\n",
    "    \"\"\"An agent that keeps track of what locations are clean or dirty.\"\"\"\n",
    "    model = {loc_A: None, loc_B: None}\n",
    "\n",
    "    def program(percept):\n",
    "        location, status = percept\n",
    "        # TODO Aufgabe 2\n",
    "        return None\n",
    "    return Agent(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize environment\n",
    "e = TrivialVacuumEnvironment()\n",
    "# add an agent to our environment\n",
    "e.add_thing(TraceAgent(ModelBasedVacuumAgent()))\n",
    "# execute our environment and the agent for five discrete timesteps\n",
    "e.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3\n",
    "Erweitern Sie die Implementierung der VacuumEnvironment, sodass es beliebig viele, auf einem 2D-Gitter angeordnete Positionen gibt. Erweitern Sie auch die Implementierung der beiden Agenten entsprechend, sodass diese sinnvoll in der neuen Umgebung agieren können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedTrivialVacuumEnvironment(Environment):\n",
    "\n",
    "    \"\"\"This environment has two locations, A and B. Each can be Dirty\n",
    "    or Clean. The agent perceives its location and the location's\n",
    "    status. This serves as an example of how to implement a simple\n",
    "    Environment.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Todo\n",
    "        self.status = None\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return [Wall, Dirt, ReflexVacuumAgent, RandomVacuumAgent,\n",
    "                TableDrivenVacuumAgent, ModelBasedVacuumAgent]\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Dirty/Clean).\"\"\"\n",
    "        return (agent.location, self.status[agent.location])\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status; track performance.\n",
    "        Score 10 for each dirt cleaned; -1 for each move.\"\"\"\n",
    "        #Todo\n",
    "        pass\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Agents start in either location at random.\"\"\"\n",
    "        return random.choice([loc_A, loc_B])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
