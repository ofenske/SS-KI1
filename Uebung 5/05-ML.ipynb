{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ea447f-f229-4a64-908d-1e632e4c28dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Maschinelles Lernen\n",
    "Heute werden wir uns mit dem Thema \"Maschinelles Lernen\" beschäftigen. Dazu schauen wir uns zunächst kurz an, welche Datenstruktur wir in Python verwenden können, um unsere Daten zunächst zu explorieren und vorzubereiten. \n",
    "\n",
    "Anschließend schauen wir uns ein einfaches Klassifikationsproblem an und probieren verschiedene Klassifikationsalgorithmen aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f30d8-825f-44fe-be84-770d43ec0b92",
   "metadata": {},
   "source": [
    "## 5.1. Pandas\n",
    "\n",
    "Ein weit verbreitetes Python-Paket für Datenmanagement und -analyse ist `pandas`. Die grundlegende Datenstruktur die dieses Paket bereitstellt ist das Data Frame. Ein Data Frame ist eine Tabelle, die im Prinzip so verwendet werden kann wie eine Tabelle in einer relationalen Datenbank. So können z.B. Zeilen oder Spalten (oder beides) selektiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6488c-ec63-4957-81b1-b0a4ba205259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'Dave', 'Eve'],\n",
    "        'Alter': [25, 30, 35, 40, 45],\n",
    "        'Stadt': ['Berlin', 'München', 'Hamburg', 'Frankfurt', 'Köln']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# show complete dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95cff74-b3a3-479a-af29-78c8abdd6be3",
   "metadata": {},
   "source": [
    "Wir können uns auch nur die ersten oder letzten Zeilen des DataFrames anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68cd3f-4915-4cab-8fd7-99decdb5567b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Die ersten zwei Zeilen: \\n {df.head(2)}\\n\")\n",
    "print(f\"Die letzten zwei Zeilen: \\n {df.tail(2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac44525-a900-4fb6-a8d5-dea38f6ab0a5",
   "metadata": {},
   "source": [
    "Weitere Informationen über unser DataFrame können wir uns mit folgenden Methoden holen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8bae2-ded6-4ea6-89c4-6c6b86c444f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Anzeigen der Spaltennamen\n",
    "print(\"\\nSpaltennamen:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Anzeigen der Informationen zum DataFrame\n",
    "print(\"\\nInfo zum DataFrame:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2995d9f-cbb4-40a4-9c56-d4f6be84c735",
   "metadata": {},
   "source": [
    "### Zeilen und Spalten auswählen\n",
    "\n",
    "Mit pandas können einfach bestimmte Zeilen und Spalten aus dem Data Frame ausgewählt werden. Eine Option besteht darin, Spalten über ihren Namen auszuwählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282e8ae-e038-47ee-ab02-6e9f8ad6ba7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = df.loc[:,\"Name\"]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44975173-d8b2-49e7-84ed-01062ae42807",
   "metadata": {},
   "source": [
    "Der `:` steht für \"Wähle alle Zeilen\". Wenn nur eine einzige Spalte gewählt wird, ist das Ergebnis vom Typ `Series`, ansonsten ist das Ergebnis wieder ein Data Frame. Spalten können auch über ihren Index ausgewählt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfccccb-c57e-4fe3-a9f6-04e6ebae13fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mult_columns = df.iloc[:,1:3]\n",
    "mult_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f326750-cc8b-48f6-8e58-32957e23c854",
   "metadata": {},
   "source": [
    "Auf Zeilen kann auf die gleiche Art zugegrifen werden. Der folgende Ausdruck liefert beispielsweise die ersten 5 Zeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a58750-f32e-4927-b786-ccb3bb58c0b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b6ddb-2573-46d9-bbd6-da23b86f1fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[0:4,[\"Alter\", \"Stadt\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f1e4d-aad1-4841-adfd-b49771b93a0d",
   "metadata": {},
   "source": [
    "Eine andere praktische Möglichkeit besteht darin, Zeilen oder Spalten über Bool'sche Ausdrücke auszuwählen. Der folgende Ausdruck liefert z.B. alle Zeilen, bei denen der Wert von  `Alter` kleiner als 36 ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd583ebe-ac41-4b30-b8fd-a23a667a5e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df['Alter'] < 36]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd15c86-3831-4dd9-b79a-9d827e191a6d",
   "metadata": {},
   "source": [
    "### Werte Einfügen\n",
    "\n",
    "Das Einfügen von Werten in ein Data Frame funktioniert genau so. Der folgende Ausdruck setzt alle Werde der Spalte  `Sensor_T8_Acceleration_Y`, die kleiner als 0 sind, auf den Wert 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25088c51-bce3-41d8-bed6-f4fd9e199bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hinzufügen einer neuen Spalte\n",
    "df['Beruf'] = ['Ingenieur', 'Lehrer', 'Arzt', 'Anwalt', 'Designer']\n",
    "print(\"DataFrame nach Hinzufügen der Spalte 'Beruf':\")\n",
    "print(df)\n",
    "df.loc[len(df)] = ['Klaus', 12, 'Rostock', 'Informatiker']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c5d8a-01ef-49ad-8922-b68a3514504a",
   "metadata": {},
   "source": [
    "### Speichern und Laden von DataFrames\n",
    "Wir können DataFrames auch in CSV-Dateien speichern oder Daten aus CSV-Dateien in ein DataFrame importieren: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fddf0-ab82-4e62-9046-ddb76b9b501d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Speichern des DataFrames in einer CSV-Datei\n",
    "df.to_csv('daten.csv', index=False)\n",
    "print(\"\\nDataFrame wurde in 'daten.csv' gespeichert.\")\n",
    "\n",
    "# Speichern des DataFrames in einer CSV-Datei\n",
    "df = pd.read_csv('iris.csv', index_col=0)\n",
    "print(f\"\\nEin neues DataFrame wurde aus der Datei 'iris.csv' geladen: \\n {df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4333994-d1ac-4d69-a796-c0a5f5b9446b",
   "metadata": {},
   "source": [
    "## Maschinelles Lernen\n",
    "Für das Maschinelle Lernen in Python stehen Ihnen unterschiedliche Packages zur Verfügung. Eines dieser Packages ist scikit-learn, welches fertige Implementierung von verschiedenen ML-Verfahren anbietet. Im weiteren Verlauf der Übung werden wir zunächst sehen aus welchen Schritten eine klassische ML-Pipeline besteht und wie diese mithilfe von Pandas und scikit-learn umgesetzt werden kann.    \n",
    "\n",
    "Zunächst beginnen wir damit die benötigten Bibliotheken zu importieren und unseren Datensatz aus einer CSV-Date zu laden:   \n",
    "\n",
    "Aufgabe: Importieren Sie die Daten aus der Datei `iris.csv` in eine DataFrame. Schauen sie sich anschließend die ersten paar Zeilen des DataFrame an und lassen Sie sich eine statistische Zusammenfassung aller Spalten generieren.    \n",
    "\n",
    "Zusatz: Überprüfen Sie das DataFrame auf fehlende Werte. Wie können Sie gegebenenfalls Null-Werte ersetzen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e3ba2-b864-4cdf-8d1a-adc395680ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importieren der erforderlichen Bibliotheken\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Importieren von Daten aus einer CSV-Datei\n",
    "data = \"Implement me!\"\n",
    "\n",
    "# 2. Datenexploration\n",
    "print(\"Erste paar Zeilen des DataFrames:\")\n",
    "print(\"Implement me!\")\n",
    "\n",
    "print(\"\\nStatistische Zusammenfassung:\")\n",
    "print(\"Implement me!\")\n",
    "\n",
    "print(\"\\nAnzahl der fehlenden Werte pro Spalte:\")\n",
    "print(\"Implement me!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab272d45-0527-4084-ae35-cfae7e6f0538",
   "metadata": {},
   "source": [
    "Nachdem wir die ersten beiden Schritte (Importieren der Daten, Exploration der Daten) erledigt haben, müssen wir die Daten für das Training des Klassifikators vorbereiten.    \n",
    "\n",
    "Aufgabe: Was müssen wir nun mit den Daten machen, um sie anschließend für das Training eines Klassifikators verwenden zu können?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40f024-f046-43a8-922b-afc63e236cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Datenvorbereitung\n",
    "# Aufteilen der Daten in Features und Zielvariable\n",
    "X = \"Implement me!\"\n",
    "y = \"Implement me!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33e0f3-492b-4e5b-a501-395632240f19",
   "metadata": {},
   "source": [
    "Nachdem wir nun auch den dritten Schritt, die Datenvorbereitung, erleidgt haben, können schlussendlich unseren Klassifikator trainieren. Wir verwenden hier zunächst den `DecisionTreeClassifier`. Nachdem diesen trainiert haben, lassen wir uns eine Zusammenfassung über die Qualität unseres Klassifikators ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bf049-e64f-43be-a7b1-11c59707018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training und Evaluation eines Klassifikators\n",
    "# Aufteilen der Daten in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialisieren des Klassifikators\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Trainieren des Klassifikators\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen für die Testdaten\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Auswertung der Vorhersagen\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Confusion matrix: \\n {cm}')\n",
    "print(f'Classification report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d8b00-6b3d-45fe-be61-745b2afb5c05",
   "metadata": {},
   "source": [
    "## Titanic-Challenge\n",
    "Programmieren Sie nun einen Klassifikator für die Titanic-Challenge. Dabei soll ihr Klassifikator vorhersagen können, ob ein Passagier überlebt oder nicht. Verwenden Sie dazu den gegebenen Titanic-Datensatz und führen Sie alle Schritte durch, die Sie in dieser Übung kennengelernt haben. Auf welche Accuracy kommen Sie am Ende? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32173c2-a921-43d4-be4c-6deb31fe55e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importieren der erforderlichen Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import ssl\n",
    "\n",
    "# SSL-Verifizierung deaktivieren\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 1. Importieren der Daten\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# 2. Datenexploration\n",
    "\n",
    "print(\"\\nStatistische Zusammenfassung:\")\n",
    "print(\"Implement me!\")\n",
    "\n",
    "print(\"\\nAnzahl der fehlenden Werte pro Spalte:\")\n",
    "print(\"Implement me!\")\n",
    "\n",
    "# 3. Datenvorbereitung\n",
    "data = \"Implement me!\"\n",
    "\n",
    "# 4. Training und Evaluation eines Klassifikators\n",
    "# Initialisieren des Klassifikators\n",
    "classifier = \"Implement me!\"\n",
    "\n",
    "# Trainieren des Klassifikators\n",
    "\"Implement me!\"\n",
    "\n",
    "# Vorhersagen für die Testdaten\n",
    "y_pred = \"Implement me!\"\n",
    "\n",
    "# Auswertung der Vorhersagen\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Confusion matrix: \\n {cm}')\n",
    "print(f'Classification report: \\n {report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lehre-oZkq39sg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
